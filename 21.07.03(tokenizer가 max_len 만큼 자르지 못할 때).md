일단, 왜 이런 에러가 발생하는지 모르겠다. 분명히 tokenizer에 max_len=512로 주고 truncate=True로 했는데, 왜 그 길이 이상으로 나오는지...

