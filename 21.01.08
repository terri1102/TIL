베이즈 정리의 이해

$$
P(H|E) = \frac{P(H\cap E)}{P(E)}
$$
[^ ]: P(H|E) :  P(Hypoothesis given the evidence)

조건부 확률을 구할 때 사용되며, 가설 검정시 Evidence가 주어졌을 때, Hypothesis가 참인 확률이라고 해설할 수 있다.
사전확률(Prior) 초기 예상값 -> 가설과 조건을 만족하는 데이터 비율(Likelihood) -> 사후확률(Posterior)
Evidence는 사전확률을 대체하는 것이 아닌 업데이트하는 것이며 시행을 반복할 수록 사후확률은 더 높아지고 모델은 정교해진다.

TPR** : True Positive Rate (=**민감도**, true accept rate)
**1인 케이스에 대해 1로 잘 예측한 비율.(암환자를 진찰해서 암이라고 진단 함)**

FPR** :  False Positive Rate (**=1-특이도**, false accept rate)
**0인 케이스에 대해 1로 잘못 예측한 비율.(암환자가 아닌데 암이라고 진단 함)**

#마르코 연쇄 몬테카를로법(MCMC) Markov Chain Monte Carlo
어떤 목표 확률분포(Target Probability Distribution)로부터 랜덤 샘플을 얻는 방법

*이 개념이 지금 어려운 이유: 선수지식이 필요함...전이행렬, 포아송 분포, 베르누이 시행, 몬테카를로 방법, 마르코 체인


마르코프 연쇄 몬테카를로 방법(무작위 행보 몬테 카를로 방법 포함)은 마르코프 연쇄의 구성에 기반한 확률 분포로부터 
원하는 분포의 정적 분포를 갖는 표본을 추출하는 알고리즘의 한 부류이다. 
큰 수의 단계(step) 이후에 연쇄의 상태는 목표로 하는 분포로부터 추출된 표본처럼 사용될 수 있다. 표본의 품질은 단계 수의 함수로 개선된다. 
일반적으로 원하는 특성을 갖는 마르코프 연쇄를 구성하는 것은 어렵지 않다. 
보다 어려운 문제는 수용할 만한 오차 범위의 정적 분포로 수렴하는데까지 얼마나 많은 단계가 필요한지를 결정하는 것이다. 
좋은 연쇄는 임의의 위치에서부터 시작하여 정적 분포에 빠르게 도달하는 빠른 혼합(mixing)을 가질 것이며, 이에 대해서는 마르코프 연쇄 혼합 시간에서 상세히 설명된다.
MCMC의 전형적인 사용은 목표 분포를 근사하는 것이며, 여기에는 항상 시작 위치로부터의 약간의 잔여 효과(residual effect)가 존재한다.
이 알고리즘의 가장 일반적인 적용 예는 다차원 적분을 수치적으로 계산하는 것이다.
마코프 프로세스는 시스템의 미래상태가 현재의 상태만 주어지면 과거의 상태와 무관하게 결정되는 확률과정을 말한다
이건 랜덤워크 가설이랑 똑같네..
pymc3
https://4four.us/article/2014/11/markov-chain-monte-carlo
